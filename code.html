<!DOCTYPE html>
<html>

<head>
    <title>Dima Damen, Professor of Computer Vision, University of Bristol</title>
    <link href='https://fonts.googleapis.com/css?family=Vollkorn' rel='stylesheet' type='text/css'>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <script src="https://code.jquery.com/jquery-1.11.3.min.js"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-7551853-2', 'auto');
  ga('send', 'pageview');

</script>
    <style>
      body {
      font-family: 'Vollkorn', sans-serif;
      }

      .subheading {
      font-size: 120%;
      }

      h2 {
      clear: left;
      margin-top: 1em;
      }
      
      h3 {
      clear: left;
      margin-top: 1em;
      }
      
      img {
      float: left;
      height: 12em;
      margin-right: 1em;
      margin-bottom: 3em;
      }

      p {
      margin: 0.5em;
      }

      nav {
      margin-top: 3em;
      margin-bottom: 1em;
      }
        
        a:visited {color:#006633}
        a:link {color:#006633}
        a:hover {color: #FF0000}
        
        h1,h2,h3{
            color:#006633
        }

    </style>
  </head>
  
  <body>
    <h1>Dima Damen</h1>

    <div class="subheading">
      <img src="Dima2019_s.jpg" />
      Professor of Computer Vision, 
      <a href="http://www.cs.bris.ac.uk">Department of Computer Science</a>,<br/>
      <a href="http://www.bris.ac.uk/vi-lab/">Visual Information Laboratory</a>,
      <a href="http://www.bristol.ac.uk">University of Bristol</a>
        <br/><br/>
      EPSRC Early Career Fellow (2020-2025)
    </div>

    <nav>
      Jump to: 
      <a href="index.html#Projects">Research</a> |
      <a href="publications.html">Publications</a> |
      <a href="about.html">Bio&amp;Group</a> |
      <a href="code.html">Datasets and code</a> |
      <a href="talks.html">Talks</a> |
      <a href="teaching.html">Teaching</a> |
      <a href="contact.html">Contact</a>
    </nav>
      
      <h2>EPIC-KITCHENS</h2>
      <p>EPIC-KITCHENS: 20M Frames, full HD, head-mounted, 45 kitchens from 4 cities (in North America and Europe). FULLY annotate. <br/>
          Dataset from: <a href="http://epic-kitchens.github.io">http://epic-kitchens.github.io</a></p>
      
      <p>The dataset is the first of its kind, in size, annotations, diversity and unscripted nature of its collection. It is accompanied by challenge leaderboards to allow comparative evaluation of methods on 6 benchmarks. Since its first-version release in 2018, the dataset has: 2.4K unique downloads from 54 countries (most downloaded dataset from UoB data.bris), 1.5K submissions to challenge leaderboards (by May 2021), 410 peer-reviewed citations.</p>
      
                  <h2>Published Datasets</h2>
      <ul>
          <li><a href="https://drive.google.com/file/d/1oX0dPM5IP638nB0YHt4L70aigIdqqpYr/view">EPIC-SKILLS</a> (2018)</li>
          <li><a href="https://github.com/FarnooshHeidari/CompletionDetection">Moment of Completion in Actions</a> - 16 action labels for UCF101, HMDB and RGBD-AC (2018)</li>
          <li><a href="http://dx.doi.org/10.5523/bris.66qry08cv1fj1eunwxwob3fjz">RGB-D Action Completion Dataset</a> (2016)</li>
          <li><a href="BEOID">Bristol Egocentric Object Interactions Dataset</a> (2014)</li>
          <li><a href="http://data.bris.ac.uk/data/dataset/bgresiy3olk41nilo7k6xpkqf">Quality of Motion - Staircase Dataset</a> (2014)</li>
          <li><a href="http://www.cs.bris.ac.uk/Publications/pub_master.jsp?id=2001575">30 Textureless Tools and Objects Dataset</a> (2012)</li>
          <li><a href="./BaggageDetection/AnnotationPETS2006.zip">Annotations of the PETS 2006 dataset for carried objects (2008)</a></li>
          </ul>
      
      <h2>Published Code</h2>
      <ul>
          
          <li>
<h3>Data Acquisition and Registration from two facing Microsoft Kinects</h3>
      <p>C++ implementation for capturing and registrating 3D models from two frontly facing Kinects [Author: Vahid Soleimani].</p>
      <p><a href="https://github.com/BristolVisualPFT/3D_Data_Acquisition_Registration_Using_Kinects/tree/master/Double_opposing_Kinects">Version 1.0 is now available [Oct 2016]</a></p>
          </li>
          
          <li>
<h3>Real-Time Learning and Detection of Texture-Minimal Objects</h3>
      <p>C++ Linux-based code for real-time learning and detection of texture-minimal objects.</p>
          <p><a href="http://youtu.be/4rPjN1mcKGc" target="new">Video on how to run the detector is available on Youtube</a></p>
      <p><a href="MultiObjDetector_code.zip">Version 1.2 (bug-fixed and performance improved) C++ Source code - Aug 2014</a></p>
<p><a href="DetectMe.apk">Android (4.0+) .apk file is now available [Aug 2014]</a></p>
          </li>
      
          <li>
      <h3>Carried Object Detector</h3>
              <p>MATLAB code is available with details of how to use it <a href="./BaggageDetection/LeedsBaggageDetector.zip">download (3.0MB)</a></p>
<p>A short sequence from PETS2006 to test the code - <a href="./BaggageDetection/Set1Ex.zip">download (3.9MB)</a></p>
              </li>
          
          <li>
              <h3>DS-KCF Real-Time RGB-D Tracker</h3> (Developed by: Massimo Camplani)
              <p><a href="http://data.bris.ac.uk/data/dataset/16vbnj3im1ygi1sh0yd0mt4lp0">MATLAB code is available with details of how to use it</a></p>
              <p>C++ code coming soon...</p>
          </li>
          </ul>
      


</html>
