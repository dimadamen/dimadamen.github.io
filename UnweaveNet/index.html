<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">

<!-- Begin Jekyll SEO tag v2.6.1 -->
<title>UnweaveNet | Unweaving Activity Stories</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Play Fair" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Frame Attributions in Video Models" />
<meta property="og:description" content="Frame Attributions in Video Models" />
<link rel="canonical" href="https://play-fair.willprice.dev/" />
<meta property="og:url" content="https://play-fair.willprice.dev/" />
<meta property="og:site_name" content="Play Fair" />
<script type="application/ld+json">
{"@type":"WebSite","headline":"UnweaveNet","url":"https://dimadamen.github.io/UnweaveNet","description":"Unweaving Activity Stories","name":"Play Fair","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <link rel="stylesheet" href="style.css?v=5f4863822ac400a1c41d9d2780f2764299edd032">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">UnweaveNet</h1>
      <h2 class="project-tagline">Unweaving Activity Stories</h2>
        <h2 class="project-tagline">CVPR 2022 Paper</h2>
      
      
    </section>

    <section class="main-content">
      <section style="text-align: center">
<div class="authors" style="font-size: 32px;"><a href="https://www.willprice.dev">Will Price</a>, <a href="http://www.cs.columbia.edu/~vondrick/">Carl Vondrick</a> <a href="https://dimadamen.github.io/">Dima Damen</a></div>
<a href="http://www.bris.ac.uk/engineering/departments/computerscience/">University of Bristol</a>
</section>

<h2 id="abstract">Abstract</h2>
<div class="centered ">
  <img width="90%" src="concept.png" alt="UnweaveNet" />
</div>
<p><i>Our lives can be seen as a complex weaving of activi- ties; we switch from one activity to another, to maximise our achievements or in reaction to demands placed upon us. Observing a video of unscripted daily activities, we parse the video into its constituent activity <b>threads</b> through a process we call <b>unweaving</b>. To accomplish this, we introduce a video representation explicitly capturing activity threads called a thread bank, along with a neural controller capable of detecting goal changes and resuming of past activities, together forming <b>UnweaveNet</b>. We train and evaluate UnweaveNet on sequences from the unscripted egocentric dataset EPIC-KITCHENS. We propose and showcase the effi- cacy of pretraining UnweaveNet in a self-supervised manner.</i></p>

<div class="centered">

<h2>CVPR 2022 Talk (June 2022)</h2>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Fbod60urVaA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
    
<h2>Supplementary Video (Mar 2022)</h2>
<iframe width="560" height="315" src="https://www.youtube.com/embed/qgehCPTD9vA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>

<h2 id="demo">Dataset</h2>

<p>You can find the annotations for <a href="http://epic-kitchens.github.io/">EPIC-KITCHENS-100</a> threads
<a href="https://github.com/willprice/activity-stories">here</a>.</p>


<hr />

<h2 id="bibtex">BibTeX</h2>

<div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@InProceedings</span><span class="p">{</span><span class="nl">Price_2022_CVPR</span><span class="p">,</span>
    <span class="na">author</span>        <span class="p">=</span> <span class="s">{Price, Will and Vondrick, Carl and Damen, Dima}</span><span class="p">,</span>
    <span class="na">title</span>         <span class="p">=</span> <span class="s">{UnweaveNet: Unweaving Activity Stories}</span><span class="p">,</span>
    <span class="na">booktitle</span>     <span class="p">=</span> <span class="s">{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}</span><span class="p">,</span>
    <span class="na">year</span>          <span class="p">=</span> <span class="s">{2022},</span>
    <span class="na">pages</span>          <span class="p">=</span> <span class="s">{13770-13779},</span>
<span class="p">}</span>
</code></pre></div></div>

<h2 id="downloads">Downloads</h2>

<ul>
  <li>Annotations <a href="https://github.com/willprice/activity-stories">[Github]</a></li>
 <li>Paper <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Price_UnweaveNet_Unweaving_Activity_Stories_CVPR_2022_paper.pdf">[PDF]</a>
<a href="https://openaccess.thecvf.com/content/CVPR2022/supplemental/Price_UnweaveNet_Unweaving_Activity_CVPR_2022_supplemental.zip">[Supplementary]</a>
<a href="https://arxiv.org/abs/2112.10194">[ArXiv]</a></li>
</ul>

<h2 id="acknowledgements">Acknowledgements</h2>

<p>Funded by <a href="https://epsrc.ukri.org/">EPSRC</a> National Productivity Investment Fund (NPIF) Doctoral Training Programme, <a href="https://gow.epsrc.ukri.org/NGBOViewGrant.aspx?GrantRef=EP/T004991/1">EPSRC UMPIRE (EP/T004991/1)</a> and the NSF NRI Award #2132519</p>


      <footer class="site-footer">
        
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
      </footer>
    </section>

    
  </body>
</html>
