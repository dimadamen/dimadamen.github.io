<html>

<head>
<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
     <style>
      body {
      font-family: 'Vollkorn', sans-serif;
      }

      .subheading {
      font-size: 120%;
      }

      h2 {
      clear: left;
      margin-top: 1em;
      }
      
      h3 {
      clear: left;
      margin-top: 1em;
      }
      
      img {
      margin-right: 1em;
      margin-bottom: 3em;
      }

      p {
      margin: 0.5em;
      }

      nav {
      margin-top: 3em;
      margin-bottom: 1em;
      }
        
        a:visited {color:#006633}
        a:link {color:#006633}
        a:hover {color: #FF0000}
        
        h1,h2,h3{
            color:#006633
        }

    </style>
<script type="text/javascript">
try {
var pageTracker = _gat._getTracker("UA-7551853-2");
pageTracker._trackPageview();
} catch(err) {}</script>
<title>Dima Damen - Computer Vision Group - University of Bristol</title>
<link rel="stylesheet" href="simple.css"> 
</head>

<body topmargin="15" leftmargin="15">
<h1>Who's Better, Who's Best: Skill Determination in Video using Deep Ranking</h1>
<h2>March 2017</h2>

<p>Hazel Doughty, <a href="http://www.cs.bris.ac.uk/~damen">Dima Damen</a>, <a href="http://www.cs.bris.ac.uk/~wmayol/">Walterio Mayol-Cuevas</a></p>

<table width=90%>
<tr>
<td valign="middle">

<p>We present a method for assessing skill of performance from video, for a variety of tasks, ranging from drawing to surgery
and rolling dough. We formulate the problem as pairwise and overall ranking of video collections, and propose a supervised deep 
ranking model, which characterises the relative differences in performance between a pair of videos. Each pair consists of two videos:
one ranked higher than the other by <i>human annotators</i> in terms of the skill displayed. By assigning videos a relative score of
 skill for the given task, we can create a <i>skill ranking</i> for a set of videos. We utilise a 
two-stream Temporal Segment Network to capture both the type and quality of motions and the evolving task state. 

<p>Results demonstrate 
our method is applicable to a variety of tasks, with the percentage of correctly ordered pairs of videos ranging from 70%
to 82% for all four datasets. We demonstrate the robustness of our approach via sensitivity analysis of its parameters. We see 
this work as effort toward the automated and objective organisation of <i>how-to</i> videos and overall, generic skill determination in video.</p>

</td>
<td valign="top" width=5%></td>
<td valign="top" width=40%>
    <p><img src="concept.png" alt="Skill Determination Overview" width=450></p>
</td></tr></table>
<table width=90%>
    <br/>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/GO5pBQA5PhI" frameborder="0" allowfullscreen></iframe>
<tr>
<td valign=top align=left>
<br/>
<table width="100%" cellpadding="0">
<tbody><tr>

<h2>Publications</h2>
<p>Hazel Doughty, Dima Damen and Walterio Mayol-Cuevas (2017). Who's Better, Who's Best: Skill Determination in Video using Deep Ranking. <a href="skill_determination.pdf" download="skill_determination.pdf">PDF</a> | <a href="https://arxiv.org/abs/1703.09913">arxiv</a></p>

<h2>Datasets</h2>
The datasets for the Drawing and Chopstick-Using tasks will be made publically available alongside the annotated pairs for each dataset.


