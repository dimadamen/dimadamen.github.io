<!DOCTYPE html>
<html>
  <head>
    <title>Dima Damen, Associate Prof (Reader) in Computer Vision, University of Bristol</title>
    <link href='https://fonts.googleapis.com/css?family=Vollkorn' rel='stylesheet' type='text/css'>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <script src="https://code.jquery.com/jquery-1.11.3.min.js"></script>
        <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-7551853-2', 'auto');
      ga('send', 'pageview');

    </script>
    <style>
      body {
      font-family: 'Vollkorn', sans-serif;
      }

      .subheading {
      font-size: 120%;
      }

      h2 {
      clear: left;
      margin-top: 1em;
      }
      
      h3 {
      clear: left;
      margin-top: 1em;
      }
      
      img {
      float: left;
      height: 12em;
      margin-right: 1em;
      margin-bottom: 3em;
      }

      p {
      margin: 0.5em;
      }

      nav {
      margin-top: 3em;
      margin-bottom: 1em;
      }
        
        a:visited {color:#006633}
        a:link {color:#006633}
        a:hover {color: #FF0000}
        
        h1,h2,h3{
            color:#006633
        }

    </style>
  </head>
  
  <body>
    <h1>Dima Damen</h1>

    <div class="subheading">
      <img src="Dima2.jpg" />
      Associate Professor (Reader) at the
      <a href="http://www.cs.bris.ac.uk">Department of Computer Science</a>,<br/>
      <a href="http://www.bris.ac.uk/vi-lab/">Visual Information Laboratory</a>,
      <a href="http://www.bristol.ac.uk">University of Bristol</a>
    </div>

    <nav>
      Jump to: 
      <a href="index.html#Projects">Research</a> |
      <a href="publications.html">Publications</a> |
      <a href="code.html">Datasets and code</a> |
      <a href="talks.html">Talks</a> |
      <a href="teaching.html">Teaching</a> |
      <a href="about.html">About me</a> |
      <a href="contact.html">Contact</a>
    </nav>
    
    <h2>News</h2>
      <p>Sep 2018: EPIC-KITCHENS presented as Oral at ECCV 2018 - camera ready available <a href="https://arxiv.org/abs/1804.02748">Arxiv</a>, <a href="http://epic-kitchens.github.io/">Webpage</a></p>
      <p>Sep 2018: Leaderboards for the EPIC-KITCHENS challenges on CodaLab are now <a href="https://epic-kitchens.github.io/2018#challenges">open</a></p>
      <p>Sep 2018: Two papers presented at BMVC 2018. <a href="https://arxiv.org/abs/1805.06749">Action Completion</a> (<a href="https://github.com/FarnooshHeidari/CompletionDetection">Dataset</a>) and <a href="https://arxiv.org/abs/1806.08152">CaloriNet</a></p>
      <p>Aug 2018: EPIC-SKILLS dataset, for our CVPR2018 paper is now <a href="./Skill/index.html#dataset"></a>online</p>
      <p>Aug 2018: Programme for <a href="http://www.eyewear-computing.org">EPIC@ECCV2018 workshop</a> is now available. Join us in Munich on Sep 9th</p>
      <p>July 2018: Will be giving a keynote at <a href="http://www.visapp.visigrapp.org">VISAPP 2019 next Feb in Prague</a></p>
      <p>July 2018: Looking forward to giving a tutorial on <b>egocentric vision</b> as part of the <a href="https://cvss-uea.uk">BMVA Summer School</a> on July 5th, University of East Anglia.</p>
      <p>Apr 2018: EPIC-KITCHENS 2018 goes live today: 11.5M Frames, full HD, 60fps, head-mounted, 32 kitchens from 4 cities (in North America and Europe), 10 nationalities. FULLY annotated: 40K action segments, 454K object bounding boxes. Dataset: <a href="http://epic-kitchens.github.io">http://epic-kitchens.github.io</a> Details at: <a href="http://arxiv.org/abs/1804.02748">Arxiv</a></p>
      <p>Apr 2018: Our paper "Human Routine Change Detection using Bayesian Modelling" accepted at ICPR2018, to be presented in Beijing this August. <a href="./Routine/">Details</a></p>
      <p>Feb 2018: Our paper "Who's Better, Who's Best" accepted at CVPR2018, to be presented in Salt Lake city this June. <a href="./Skill/">Details</a></p>
      <p>Feb 2018: Congrats to <a href="http://www.irc-sphere.ac.uk/uob-yangdi">Yangdi Xu</a> for passing his PhD viva with minor corrections</p>
    <p><a id="showOlderNews" href="#olderNews">Older news...</a></p>
    <div id="olderNews">
      <a name="olderNews" />
              <p>Jan 2018: Serving on the High Performance Computing exec board at UoB</p>
      <p>Oct 2017: Selected as outstanding reviewer at ICCV 2017</p>
      <p>Oct 2017: Well-attended <a href="http://www.eyewear-computing.org/EPIC_ICCV17/">Second Int. Egocentric Perception Interaction and Computing (EPIC) workshop alongside ICCV in Venice</a></p>
      <p>Oct 2017: Our paper "Trespassing the Boundaries: Labeling Temporal Bounds for Object Interactions in Egocentric Video" was presented in ICCV - <a href="./Trespass/">details</a></p>
      <p>Oct 2017: Our paper "Recurrent Assistance: Cross-Dataset Training of LSTMs on Kitchen Tasks" was presented at ACVR - <a href="./LSTMT/acvr2017.pdf">pdf</a></p>
      <p>Sep 2017: <a href="https://comsm0018-applied-deep-learning.github.io/">Unit details for the <font color="red"><b>new</b></font> Applied Deep Learning M level unit</a> - <a href="http://www.bris.ac.uk/unit-programme-catalogue/UnitDetails.jsa?ayrCode=17/18&unitCode=COMSM0018">Uni Catalogue</a>
      <p>Sep 2017: Serving as <a href="https://www.journals.elsevier.com/pattern-recognition/editorial-board">associate editor for Pattern Recognition</a></p>
      <p>Aug 2017: Happy to be working as a consultant with Bristol's Cookpad on developing their Computer Vision and Machine Learning agenda</p>
              <p>Apr 2017: <a href="http://cvss.blogs.lincoln.ac.uk/programme/">6 July - Lincoln, BMVA summer school, will be giving a tutorial on Egocentric Vision</a></p>
      <p>Apr 2017: <a href="https://pintofscience.co.uk/event/rage-against-the-machine-vision">15 May - Bristol, will be giving a public talk on 'What can a wearable camera know about me?'</a></p>
              <p>Mar 2017: <a href="./Talks/DamenBMVAMar2017RGBD.pdf">Slides from my talk on Challenges and Opportunities for Action and Activity Recognition using RGBD Data</a>, BMVA Symposium are now available</p>
      <p>Feb 2017: <a href="https://onedrive.live.com/?authkey=%21AA%5Fh1NXcVe4TSyo&id=7534AF006761B2BF%21440800&cid=7534AF006761B2BF">Videos from BMVA symposium on Transfer Learning now available</a></p>
      <p>Dec 2016: <a href="TLCV/">Final programme for BMVA Symposium on Transfer Learning now available</a></p> 
    </p>
              <p>Oct 2016: <a href="https://github.com/BristolVisualPFT/3D_Data_Acquisition_Registration_Using_Kinects/tree/master/Double_opposing_Kinects">Code Released</a> for 3DV paper on acquisition and registration of point clouds using two facing Kinects </p>
      <p>Sep 2016: 3D Data Acquisition and Registration Using Two Opposing Kinects - Paper accepted at 3DV</p>
      <p>Aug 2016: Action Completion paper accepted at BMVC and dataset released - <a href="./ActionCompletion/">Project Webpage</a></p> 
        <p>Aug 2016: Nokia Technologies donation of &euro;50K <a href="http://www.bristol.ac.uk/news/2016/august/nokia-grant.html">Press release</a></p>
        <p>Aug 2016: Action Completion paper accepted at BMVC, York, Sep 2016. <a href="./ActionCompletion/">project</a></p>

              <p>July 2016: PhD students Michael Wray and Davide Moltisanti awarded second poster prize at BMVA summer school <a href="https://vilab.blogs.ilrt.org/?p=1779">news</a>
    <p>July 2016: CFP: Transfer Learning in Computer Vision - BMVA Symposium <a href="TLCV/">[details, dates and submission]</a></p>
    <p>Jun 2016: PhD opening in Computer Vision and Machine Learning (Home/EU students) - <a href="http://www.bris.ac.uk/engineering/media/grad-school/scholarships/locate.pdf">Open Until </a>, <a href="http://www.jobs.ac.uk/job/ANY901/phd-in-computer-vision-and-machine-learning-epsrc-project-locate/">ad on jobs.ac.uk</a></p>
    <p>Jun 2016: <a href="http://cvpr2016.thecvf.com/program/demos">CVPR 2016 Demo for GlaciAR</a></p>
    <p>May 2016: <a href="http://www.eyewear-computing.org/EPIC_ECCV16/">EPIC@ECCV2016 Workshop (Egocentric Perception, Interaction and Computing) Accepted.</a></p>
    <p>Apr 2016: <a href="http://gow.epsrc.ac.uk/NGBOViewPanelROL.aspx?PanelId=1-2L4MKR&RankingListId=1-2L4MKZ">EPSRC Project LOCATE</a> to be funded starting July 2016</p>
    
            <p>Mar 2016: <a href="http://arxiv.org/abs/1510.04862v2">You-Do, I-Learn: Egocentric Unsupervised Discovery of Objects and their Modes of Interaction Towards Video-Based Guidance</a> accepted at CVIU</p>
        <p>Nov 2015: <a href="http://gow.epsrc.ac.uk/NGBOViewGrant.aspx?GrantRef=EP/N013964/1">EPSRC Project GLANCE</a> to be funded starting March 2016</p>
    <p>Sep 2015: Paper "Unsupervised Daily Routine Modelling from a Depth Sensor using Bottom-Up and Top-Down Hierarchies" accepted at ACPR</p>
    <p>Sep 2015: Paper "Estimating Visual Attention from a Head Mounted IMU" presented at ISWC in Okasa, Japan</p>
    <p>Sep 2015: Paper "Real-time RGB-D Tracking with Depth Scaling Kernelised Correlation Filters and Occlusion Handling" Presented at BMVC</p>
    <p>Aug 2015: PhD Student Vahid Soleiman publishes paper on Remote Pulmonary Function Testing using a Depth Sensor at BIOCAS 2015.
      <a href="https://youtu.be/AX4BvyoKYYQ">Demo Video</a>
    <p>June 2015: PLOSONE article <a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0127769">available online</a></p>
    <p>June 2015: SI on cognitive robotics systems: concepts and applications at the Journal of Intelligent &amp; Robotic Systems is
      <a href="http://dx.doi.org/10.1007/s10846-015-0244-9">online</a></p>
    <p>Mar 2015: Interdisciplinary research internship <a href="http://www.cs.bris.ac.uk/news/news-item.jsp?nid=285">awarded for CS student Hazel Doughty</a>.</p>
      <p>Sep 2014: Paper <a href="You-Do-I-Learn">"You-Do, I-Learn: Discovering Task Relevant Objects and their Modes of Interaction from Multi-User Egocentric Video"
      </a> presented at BMVC</p>
    <p>Sep 2014: Paper <a href="Sphere/bmvc14.pdf">"Online quality assessment of human movement from skeleton data"
      </a> presented at BMVC</p>
    <p>Sep 2014: Paper <a href="You-Do-I-Learn">"Multi-user egocentric Online System for Unsupervised Assistance on Object Usage"
      </a> presented at ECCVW (ACVR 2014)</p>
    <p>Aug 2014: C++ code (improved performance v 1.2) and Android apk <a href="MultiObjDetector.htm">for real-time object detector</a> available.</p>
    <p>July 2014: The <a href="BEOID">Bristol Egocentric Object Interactions Dataset</a> has now been released</p>
    <p>July 2014: <a href="newsletter-2014-03-BookReview.pdf">Book review published in IAPR newsletter</a></p>
      <p>July 2014: Video lectures from BMVC 2013 <a href="http://videolectures.net/bmvc2013_bristol/">are now available online</a>.</p>
      <p>July 2014: Sphere project's website <a href="http://irc-sphere.ac.uk">irc-sphere.ac.uk</a> has now been released (2013-2018).</p>
      <p>May 2014: <a href="projects.htm">Project Ideas for 3G403 and 2G400 students available</a>.</p>
      <p>Feb 2014: <a href="jobs.htm">PhD Opening in Ego-centric Vision</a> - apply as soon as possible... </p>
      <p>Nov 2013: Project GlaciAR is starting funded by <a href="http://www.sait.samsung.co.kr/saithome/Page.do?method=main&pagePath=01_about/&pageName=2013gro">Samsung's GRO 2013 Awards</a></p>
      <p>Nov 2013: <a href="http://crs2013.org">Cognitive Robotics Systems (CRS 2013)</a> (<a href="http://www.iros2013.org/">IROS 2013</a> workshop), successfully concludes at Tokyo, Japan.</p>
      <p>Sep 2013: <a href="http://bmvc2013.bristol.ac.uk">BMVC 2013</a> successfully concluded at Bristol</p>
      <p>Aug 2013: Outstanding Reviewer award at <a href="http://www.avss2013.org/awards">IEEE AVSS 2013</a>.</p>
      <p>June 2013: Outstanding Reviewer award at <a href="http://www.pamitc.org/cvpr13/">IEEE CVPR 2013</a>.</p>
      <p>May 2013: New bug-fixed version (v1.1) of our Multi-Object Detector (MOD) code is now available <a href="MultiObjDetector.htm">online</a></p>
    </div>

    <a name="Projects"><h2>Research Projects</h2></a>
    
    <h3>Project <a href="http://epic-kitchens.github.io">Scaling Egocentric Vision: EPIC-KITCHENS 2018</a></h3>
          <table><tr><td width="40%">  <a href="http://epic-kitchens.github.io"><video autoplay muted loop width="100%">
          <source src="https://epic-kitchens.github.io/static/videos/04x04_vp9.webm" type="video/webm">
          <source src="https://epic-kitchens.github.io/static/videos/04x04_h265_720.mp4" type="video/mp4">
          <source src="https://epic-kitchens.github.io/static/videos/04x04_h264_720.mp4" type="video/mp4">
          Sorry, we cannot display the EPIC-Kitchens 2018 video wall as
          your browser doesn't support HTML5 video.
              </video></a></td><td valign="top">
        <p><a href="https://youtu.be/Dj6Y3H0ubDw">Video</a></p>
    <p>Scaling Egocentric Vision: The EPIC-KITCHENS Dataset. D Damen, H Doughty, G Farinella, S Fidler, A Furnari, E Kazakos, D Moltisanti, J Munro, T Perrett, W Price, M Wray. ECCV (2018). <a href="http://epic-kitchens.github.io">Webpage</a> | <a href="http://epic-kitchens.github.io">Dataset</a> | <a href="https://arxiv.org/abs/1804.02748">arxiv</a>
    </p></td></tr></table>
    
    <h3>Project <a href="./ActionCompletion/">Action Completion: A Temporal Model for Moment Detection</a></h3>
    <a href="ActionCompletion/"><img src="ActionCompletion/ActionCompletionDetectionIntro.png" /></a>
   <p><a href="https://youtu.be/Hrxehk3Sutc">Video2018</a>, <a href="https://youtu.be/iBdW-kVKMds">Video2016</a></p> 
    <p>Action Completion: A Temporal Model for Moment Detection. F Heidarivincheh, M Mirmehdi, D Damen. British Machine Vision Conference (BMVC), Sep 2018. <a href="https://arxiv.org/abs/1805.06749">Arxiv PDF</a> | <a href="https://github.com/FarnooshHeidari/CompletionDetection">Dataset</a> </p>
    <p>Beyond Action Recognition: Action Completion in RGB-D Data. F Heidarivincheh, M Mirmehdi, D Damen. British Machine Vision Conference (BMVC), Sep 2016.
     <a href="./ActionCompletion/ActionCompletion_BMVC2016.pdf">pdf</a> | <a href="./ActionCompletion/ActionCompletion_BMVC2016_abstract.pdf">abstract</a> |
      <a href="http://dx.doi.org/10.5523/bris.66qry08cv1fj1eunwxwob3fjz">Dataset</a>
    </p>
    
    <h3>Project <a href="./Skill/">Who's Better, Who's Best: Skill Determination in Video</a></h3>
    <a href="./Skill/"><img src="./Skill/concept.png" /></a>
   <p><a href="https://youtu.be/GO5pBQA5PhI">Video</a></p> 
    <p>Who's Better? Who's Best? Pairwise Deep Ranking for Skill Determination. H Doughty, D Damen, W Mayol-Cuevas. CVPR (2018). <a href="Skill/whos_better_whos_best.pdf">PDF</a> | <a href="https://arxiv.org/abs/1703.09913">arxiv</a> | <a href="./Skill/index.html#dataset">Dataset</a>
    </p>
    
    <h3>Project <a href="./Routine/">Human Routine Modelling and Change Detection</a></h3>
    <a href="./Routine/"><img src="./Routine/kitchenDataset.png" /></a>
    <p>Human Routine Change Detection using Bayesian Modelling. Y Xu, D Damen. ICPR (2018). <a href="Routine/ICPR18_XuDamen.pdf">PDF</a>
    </p>
    <p>Unsupervised Long-Term Routine Modelling using Dynamic Bayesian Networks. Y Xu, D Bull, D Damen. DICTA (2017). <a href="Routine/DICTA17_XuBullDamen.pdf">PDF</a></p>
    
    <h3>Project <a href="./Unequivocal/">Towards an Unequivocal Representation of Actions</a></h3>
    <a href="./Unequivocal/"><img src="./Unequivocal/dilemma.png" /></a>
    <p>Towards an Unequivocal Representation of Actions. M Wray, D Moltisanti, D Damen. <a href="https://arxiv.org/abs/1805.04026">ArXiv</a>, 2018.</p>
    <p>Improving Classification by Improving Labelling: Introducing Probabilistic Multi-Label Object Interaction Recognition. M Wray, D Moltisanti, W Mayol-Cuevas, D Damen. ArXiv, 2017. <a href="https://arxiv.org/abs/1703.08338">arxiv</a>
    </p>
    
    <h3>Project <a href="./Trespass/">Trespassing the Boundaries of Object Interactions</a></h3>
    <a href="./Trespass/"><img src="./Trespass/Overview.png" /></a>
   <p><a href="https://youtu.be/mWr8JJDgA3w">Video</a></p> 
    <p>Trespassing the Boundaries: Labeling Temporal Bounds for Object Interactions in Egocentric Video. D Moltisanti, M Wray, W Mayol-Cuevas, D Damen. International Conference on Computer Vision (ICCV), 2017. <a href="./Trespass/trespassing-boundaries-labeling.pdf">pdf</a> (camera ready) | <a href="https://arxiv.org/abs/1703.09026">arxiv</a>
    </p>
    
    <h3>Project <a href="./SEMBED/">Semantic Embedding for Egocentric Actions</a></h3>
    <a href="./SEMBED/"><img src="./SEMBED/Overview2.png" /></a>
   <p><a href="http://youtu.be/6bDDTIJUuic">Video</a></p> 
    <p>SEMBED: Semantic Embedding of Egocentric Action Videos. M Wray, D Moltisanti, W Mayol-Cuevas, D Damen. Egocentric Interaction, Perception and Computing (EPIC), European Conference on Computer Vision Workshops (ECCVW), Oct 2016.
     <a href="./SEMBED/ECCVW2016SEMBED.pdf">pdf</a> | <a href="BEOID">Dataset</a>
    </p>
      
    

    <h3>Project <a href="You-Do-I-Learn">You-Do, I-Learn</a></h3>
    <img src="YDIL.png" />
    <p><a href="http://www.youtube.com/watch?v=vUeRJmwm7DA">Video1 (2014)</a>, <a href="https://www.youtube.com/watch?v=USFaDjXkPfs">Video2 (2017)</a></p>
    <p>Automated capture and delivery of assistive task guidance with an eyewear computer: The GlaciAR system. T Leelasawassuk, D Damen, W Mayol-Cuevas. Augmented Human, Mar 2017
    <a href="https://arxiv.org/abs/1701.02586">pdf</a></p>
    <p>You-Do, I-Learn: Discovering Task Relevant Objects and their Modes of Interaction from Multi-User Egocentric Video. D Damen, T Leelasawassuk, O Haines, A Calway, W Mayol-Cuevas. British Machine Vision Conference (BMVC), Sep 2014.
      <a href="You-Do-I-Learn/Damen_BMVC2014.pdf">PDF</a> |
      <a href="You-Do-I-Learn/Damen_BMVC2014_abstract.pdf">Abstract</a> |
      <a href="BEOID">Dataset</a>
    </p>
                
    <p>Multi-user egocentric Online System for Unsupervised Assistance on Object Usage. D Damen, O Haines, T Leelasawassuk, A Calway, W Mayol-Cuevas. ECCV Workshop on Assistive Computer Vision and Robotics (ACVR), Sep 2014.
      <a href="You-Do-I-Learn/Damen_ACVR2014_prePrint.pdf">PDF Preprint</a>
    </p>
    
    <p class="projectPublication">Estimating Visual Attention from a Head Mounted IMU. T Leelasawassuk, D Damen, W Mayol-Cuevas. International Symposium on Wearable Computers (ISWC), Sep 2015.
      <a href="http://dx.doi.org/10.1145/2802083.2808394">PDF</a>
    </p>

    
    <h3>Project <a href="http://www.irc-sphere.ac.uk/work-package-2/DS-KCF">DS-KCF: Depth-Based Real-Time Single Object Tracker</a></h3>
    <img src="DSKCF.png" />
    <p>
      <a href="https://www.youtube.com/watch?v=yhT2PdN9BTw&amp;feature=youtu.be">Video 1</a> |
      <a href="https://www.youtube.com/watch?v=YoFMf2iARzA&amp;feature=youtu.be">Video 2</a> |
      <a href="http://data.bris.ac.uk/data/dataset/16vbnj3im1ygi1sh0yd0mt4lp0">Code</a>
    </p>

    <p>Real-time RGB-D Tracking with Depth Scaling Kernelised Correlation Filters and Occlusion Handling. M Camplani, S Hannuna, M Mirmehdi, D Damen, L Tao, T Burghardt and A Paiment. British Machine Vision Conference (BMVC), Sep 2015. <a href="http://bmvc2015.swansea.ac.uk/proceedings/papers/paper145/paper145.pdf">PDF</a>.</p>


    <h3>Project <a href="MultiObjDetector.htm">Real-time Learning and Detection of 3D Texture-minimal Objects</a></h3>
    <img src="multiObj.png" />
    <p><a href="https://www.youtube.com/watch?v=XGRzjAFO5Qs">Video</a> | <a href="MultiObjDetector_code.zip">Code</a></p>

    
    <p>Real-time Learning and Detection of 3D Texture-minimal Objects: A Scalable approach. D Damen, P Bunnun, A Calway, W Mayol-Cuevas. British Machine Vision Conference (BMVC), Sep 2012.      
      <a href="bmvc2012_scalable_textureless.pdf">PDF</a> |
      <a href="bmvc2012_abstract.pdf">Abstract</a> |
      <a href="MultiObjDetector_code.zip">Code</a> |
      <a href="https://www.youtube.com/watch?v=4rPjN1mcKGc">Video</a> |
      <a href="http://www.cs.bris.ac.uk/Publications/pub_master.jsp?id=2001575">Dataset</a>.
    </p>
    
    <p>Efficient Texture-less Object Detection for Augmented Reality Guidance. T Hodan, D Damen, W Mayol-Cuevas, J Matas. IEEE Int. Symposium on Mixed and Augmented Reality (ISMAR) Workshop on Visual Recognition and Retrieval for Mixed and Augmented Reality, Sep 2015.</p>
                

    <h3>Project <a href="http://www.ict-cognito.org">Egocentric Real-time Industrial Workflow</a></h3>
    <img src="cognito.png" />
    <p><a href="https://youtu.be/wqDNxhAKkNI">Video 1</a> | <a href="https://www.youtube.com/watch?v=XGRzjAFO5Qs">Video 2</a></p>
    
    <p>Cognitive Learning, Monitoring and Assistance of Industrial Workflows Using Egocentric Sensor Networks. G Bleser, D Damen, A Behera, et al. PLOSONE, June 2015
      <a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0127769">PDF</a>.</p>
                
    <p>Egocentric Real-time Workspace Monitoring using an RGB-D Camera. D Damen, A Gee, W Mayol-Cuevas, A Calway. Intelligent Robotics and Systems (IROS), Oct 2012.
      <a href="Egocentric_IROS2012.pdf">PDF</a> | <a href="https://www.youtube.com/watch?v=XGRzjAFO5Qs">Video</a>.
    </p>

    <h3>Project <a href="http://www.irc-sphere.ac.uk/work-package-2/movement-quality">Online Quality Assessment for Human Motion</a></h3>
    <img src="Quality.png" />
    <p><a href="http://www.cs.bris.ac.uk/home/palement/datasets/code_movement_quality.zip">Code</a></p>

    <p>Online quality assessment of human movement from skeleton data. A Paiment, L Tao, S Hannuna, M Camplani, D Damen and M Mirmehdi. British Machine Vision Conference (BMVC), Sep 2014.
      <a href="http://www.cs.bris.ac.uk/home/palement/articles/bmvc2014.pdf">PDF</a> | <a href="http://data.bris.ac.uk/data/dataset/bgresiy3olk41nilo7k6xpkqf">Dataset</a>.</p>

    <h3>Project <a href="./Bicycles/bikes2.htm">The Bicycle Problem</a></h3>
    <img src="bikes2.jpg" />
    <p>Explaining Activities as Consistent Groups of Events - A Bayesian Framework using Attribute Multiset Grammars. D Damen and D Hogg International Journal of Computer Vision (IJCV), 2012. <a href="http://www.springerlink.com/content/x4vm7237u646u523/">PDF</a>.</p>
    <p>Recognizing Linked Events: Searching the Space of Feasible Explanations. D Damen and D Hogg. Computer Vision and Pattern Recognition (CVPR), Miami, Florida, June 2009.
      <a href="CVPR09.pdf">PDF</a> |
      <a href="CVPR09_poster.jpg">Poster</a>
    </p>
    
    <h3>Project <a href="./BaggageDetection/baggage.htm">Detecting Carried Objects from Walking Pedestrians</a></h3>
    <img src="bags2.jpg" />
    
    <p><a href="https://www.youtube.com/watch?v=ZFPhr7mx4Mw">Video</a> |
      <a href="./BaggageDetection/LeedsBaggageDetector.zip">Code</a>
    </p>

    <p>Detecting Carried Objects from Sequences of Walking Pedestrians. D Damen and D Hogg. Pattern Analysis and Machine Intelligence (PAMI), 2012.
      <a href="http://dx.doi.org/10.1109/TPAMI.2011.205">PDF</a>.</p>

    <p>Detecting Carried Objects in Short Video Sequences. D Damen and D Hogg. European Conference on Computer Vision (ECCV), Marseille, France, Oct 2008
      <a href="DamenHoggECCV2008.pdf">PDF</a> |
      <a href="./BaggageDetection/ECCV08P.gif">Poster</a>
    </p>

    <h2>Current Students and Postdocs</h2>
    <ul>
      <li><a href="http://www.bristol.ac.uk/engineering/people/alessandro-masullo/index.html">Alessandro Masullo</a>, postdoc (SPHERE project), 2017-</li>
      <li><a href="http://www.bris.ac.uk/engineering/people/victor-ponce-lopez/index.html">Victor Ponce Lopez</a>, postdoc (SPHERE project), 2017-</li>
      <li><a href="https://youngkyoonjang.bitbucket.io">Youngkyoon Jang</a>, postdoc (GLANCE project), 2018-</li>
      <li><a href="http://willprice.org">Will Price</a>, PhD student 2017 - </li>
      <li>Evangelos Kazakos, PhD student 2017 - </li>
      <li>Jonathan Munro, PhD student 2017 - </li>
      <li>Hazel Doughty, PhD student 2016 - (Co-supervisor: Walterio Mayol-Cuevas)</li>
      <li>Miguel Fortiz, PhD student 2016 - (Co-supervisor: Walterio Mayol-Cuevas)</li>
      <li><a href="https://vilab.blogs.ilrt.org/?cmt-management-team=farnoosh-heidarivincheh">Farnoosh Heidarivincheh</a>, PhD student 2015- (Co-supervisor: Majid Mirmehdi)</li>
      <li><a href="http://www.davidemoltisanti.com/research">Davide Moltisanti</a>, PhD student 2015- (Co-supervisor: Walterio Mayol-Cuevas)</li>
      <li><a href="https://mwray.github.io">Mike Wray</a>, PhD student 2015- (Co-supervisor: Walterio Mayol-Cuevas)</li>
      </ul>
    
    <h2>Previous Students, and Postdocs</h2>
    <ul>
        <li><a href="http://www.irc-sphere.ac.uk/uob-vahid">Vahid Soleimani</a>, PhD student 2014-2018 (Co-supervisor: Majid Mirmehdi)</li>
       <li><a href="http://www.irc-sphere.ac.uk/uob-yangdi">Yangdi Xu</a>, PhD student 2013-2018</li>
       <li>Toby Perrett, postdoc (LOCATE project), 2017-2018</li>
        <li><a href="https://scholar.google.co.uk/citations?user=SfOhCKIAAAAJ&hl=en">Teesid Leelasawassuk</a>, PhD student 2011-2016</li>
        <li><a href="https://scholar.google.es/citations?user=7FrKNIIAAAAJ&hl=en">Massimo Camplani</a>, postdoc (SPHERE project), 2013-2017</li>
        <li><a href="http://www.bristol.ac.uk/engineering/people/sion-l-hannuna/index.html">Sion Hannuna</a>, postdoc (SPHERE project), 2013-2017</li>
        <li><a href="http://people.uwe.ac.uk/Pages/person.aspx?accountname=campus%5Cl3-tao">Lili Tao</a>, postdoc (SPHERE project), 2013-2017</li>
        <li><a href="http://www.swansea.ac.uk/staff/science/computer-science/paiementa/">Adeline Paiment</a>, postdoc (SPHERE project), 2013-2016</li>
   </ul>
    
    <script>
      $(function() {
	  var olderNews = $("#olderNews");
	  olderNews.hide();
	  $("#showOlderNews").click(function() {
	      olderNews.show(1000);
	  });
      });
    </script>
  </body>
</html>
